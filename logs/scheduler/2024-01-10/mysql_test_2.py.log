[2024-01-10T18:38:10.759+0000] {processor.py:153} INFO - Started process (PID=6364) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:38:10.761+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:38:10.764+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:38:10.763+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:38:10.959+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:38:11.184+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:38:11.184+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:38:11.276+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:38:11.275+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:38:11.351+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.606 seconds
[2024-01-10T18:38:41.801+0000] {processor.py:153} INFO - Started process (PID=6441) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:38:41.802+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:38:41.804+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:38:41.803+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:38:41.919+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:38:41.964+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:38:41.963+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:38:42.007+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:38:42.007+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:38:42.053+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.260 seconds
[2024-01-10T18:39:12.365+0000] {processor.py:153} INFO - Started process (PID=6517) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:39:12.367+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:39:12.368+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:39:12.368+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:39:12.533+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:39:12.565+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:39:12.564+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:39:12.698+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:39:12.697+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:39:12.824+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.466 seconds
[2024-01-10T18:39:43.641+0000] {processor.py:153} INFO - Started process (PID=6593) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:39:43.642+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:39:43.645+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:39:43.644+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:39:43.835+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:39:44.066+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:39:44.065+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:39:44.168+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:39:44.167+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:39:44.268+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.636 seconds
[2024-01-10T18:40:14.493+0000] {processor.py:153} INFO - Started process (PID=6669) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:40:14.495+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:40:14.496+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:40:14.496+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:40:14.593+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:40:14.636+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:40:14.636+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:40:14.699+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:40:14.699+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:40:14.823+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.336 seconds
[2024-01-10T18:40:45.175+0000] {processor.py:153} INFO - Started process (PID=6745) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:40:45.177+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:40:45.179+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:40:45.179+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:40:45.341+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:40:45.372+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:40:45.372+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:41:46.743+0000] {processor.py:153} INFO - Started process (PID=52) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:41:46.749+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:41:46.751+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:41:46.751+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:41:47.049+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:41:47.501+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:41:47.501+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:41:47.685+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:41:47.684+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:41:47.833+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py:639 RemovedInAirflow3Warning: DAG.full_filepath is deprecated in favour of fileloc
[2024-01-10T18:41:47.843+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:41:47.835+0000] {dagbag.py:639} ERROR - Failed to write serialized DAG: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 631, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1713, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1553, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 721, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 608, in _assert_active
    code="7s2a",
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(read_to_local_mysql) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'read_to_local_mysql', 'fileloc': '/opt/airflow/dags/mysql_test_2.py', 'fileloc_hash': 1013979720621992, 'data': '{"__version": 1, "dag": {"tags": ["mysql", "local", "test", "company"], "default_args": {"__var": {"depends_on_past": false, "retries": 1, "retry_del ... (2666 characters truncated) ... \ucc44\\uc6a9 \\uacf5\\uace0 + {{ task_instance.xcom_pull(task_ids=\\"execute_sql_and_return_result\\") }}"}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 1, 10, 18, 41, 47, 140166, tzinfo=Timezone('UTC')), 'dag_hash': '92e46179dbd58c5b22459dfaea0773c2', 'processor_subdir': None}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-01-10T18:41:47.846+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:41:47.845+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:41:47.850+0000] {processor.py:178} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 174, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 75, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 768, in process_file
    dagbag.sync_to_db(processor_subdir=self._dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 645, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 384, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 351, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 660, in sync_to_db
    self.dags.values(), processor_subdir=processor_subdir, session=session
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2701, in bulk_write_to_db
    orm_dags: list[DagModel] = with_row_locks(query, of=DagModel, session=session).all()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2773, in all
    return self._iter().all()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1713, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1553, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 721, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 608, in _assert_active
    code="7s2a",
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(read_to_local_mysql) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'read_to_local_mysql', 'fileloc': '/opt/airflow/dags/mysql_test_2.py', 'fileloc_hash': 1013979720621992, 'data': '{"__version": 1, "dag": {"tags": ["mysql", "local", "test", "company"], "default_args": {"__var": {"depends_on_past": false, "retries": 1, "retry_del ... (2666 characters truncated) ... \ucc44\\uc6a9 \\uacf5\\uace0 + {{ task_instance.xcom_pull(task_ids=\\"execute_sql_and_return_result\\") }}"}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 1, 10, 18, 41, 47, 140166, tzinfo=Timezone('UTC')), 'dag_hash': '92e46179dbd58c5b22459dfaea0773c2', 'processor_subdir': None}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-01-10T18:42:18.466+0000] {processor.py:153} INFO - Started process (PID=128) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:42:18.467+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:42:18.468+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:42:18.468+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:42:18.530+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:42:18.611+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:42:18.611+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:42:18.645+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:42:18.645+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:42:18.679+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.215 seconds
[2024-01-10T18:42:49.478+0000] {processor.py:153} INFO - Started process (PID=204) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:42:49.482+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:42:49.489+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:42:49.486+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:42:49.803+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:42:49.949+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:42:49.949+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:42:50.145+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:42:50.145+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:42:50.396+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.935 seconds
[2024-01-10T18:43:20.998+0000] {processor.py:153} INFO - Started process (PID=285) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:43:21.000+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:43:21.001+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:43:21.001+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:43:21.084+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:43:21.189+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:43:21.189+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:43:21.230+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:43:21.230+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:43:21.261+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.267 seconds
[2024-01-10T18:43:51.688+0000] {processor.py:153} INFO - Started process (PID=355) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:43:51.689+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:43:51.692+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:43:51.691+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:43:51.867+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:43:51.896+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:43:51.895+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:43:52.007+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:43:52.006+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:43:52.082+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.401 seconds
[2024-01-10T18:44:22.730+0000] {processor.py:153} INFO - Started process (PID=438) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:44:22.732+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:44:22.733+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:44:22.733+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:44:22.846+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:44:22.967+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:44:22.966+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:44:23.016+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:44:23.016+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:44:23.058+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.333 seconds
[2024-01-10T18:44:53.787+0000] {processor.py:153} INFO - Started process (PID=514) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:44:53.788+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:44:53.790+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:44:53.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:44:53.869+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:44:53.900+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:44:53.899+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:44:53.932+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:44:53.932+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:44:53.977+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.193 seconds
[2024-01-10T18:45:24.185+0000] {processor.py:153} INFO - Started process (PID=590) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:45:24.186+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:45:24.187+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:45:24.187+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:45:24.293+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:45:24.312+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:45:24.312+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:45:24.351+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:45:24.351+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:45:24.392+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.211 seconds
[2024-01-10T18:45:54.600+0000] {processor.py:153} INFO - Started process (PID=666) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:45:54.602+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:45:54.603+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:45:54.602+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:45:54.695+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:45:54.884+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:45:54.883+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:45:55.041+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:45:55.040+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:45:55.185+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.589 seconds
[2024-01-10T18:46:25.837+0000] {processor.py:153} INFO - Started process (PID=743) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:46:25.838+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:46:25.839+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:46:25.839+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:46:25.913+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:46:25.939+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:46:25.939+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:46:25.969+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:46:25.968+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:46:25.996+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.161 seconds
[2024-01-10T18:46:56.108+0000] {processor.py:153} INFO - Started process (PID=819) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:46:56.109+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:46:56.110+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:46:56.109+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:46:56.176+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:46:56.190+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:46:56.190+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:46:56.217+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:46:56.217+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:46:56.244+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.140 seconds
[2024-01-10T18:47:27.082+0000] {processor.py:153} INFO - Started process (PID=895) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:47:27.083+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:47:27.084+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:47:27.084+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:47:27.150+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:47:27.216+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:47:27.216+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:47:27.242+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:47:27.242+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:47:27.269+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.190 seconds
[2024-01-10T18:47:58.047+0000] {processor.py:153} INFO - Started process (PID=971) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:47:58.049+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:47:58.051+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:47:58.050+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:47:58.205+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:47:58.259+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:47:58.258+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:47:58.336+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:47:58.336+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:47:58.392+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.352 seconds
[2024-01-10T18:48:28.809+0000] {processor.py:153} INFO - Started process (PID=1047) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:48:28.810+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:48:28.811+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:48:28.811+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:48:28.882+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:48:28.895+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:48:28.895+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:48:28.934+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:48:28.933+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:48:28.967+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.161 seconds
[2024-01-10T18:48:59.194+0000] {processor.py:153} INFO - Started process (PID=1123) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:48:59.195+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:48:59.196+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:48:59.196+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:48:59.280+0000] {processor.py:753} INFO - DAG(s) dict_keys(['read_to_local_mysql']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:48:59.365+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:48:59.365+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:48:59.394+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:48:59.394+0000] {dag.py:3441} INFO - Setting next_dagrun for read_to_local_mysql to None, run_after=None
[2024-01-10T18:48:59.423+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.232 seconds
[2024-01-10T18:49:17.637+0000] {processor.py:153} INFO - Started process (PID=1198) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:49:17.638+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:49:17.640+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:49:17.640+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:49:17.792+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:49:17.959+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:49:17.959+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:mysql_test_2
[2024-01-10T18:49:17.975+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:49:17.975+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:mysql_test_2
[2024-01-10T18:49:17.989+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:49:17.989+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:mysql_test_2
[2024-01-10T18:49:17.990+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:49:17.990+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:49:18.008+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:49:18.008+0000] {dag.py:2711} INFO - Creating ORM DAG for mysql_test_2
[2024-01-10T18:49:18.026+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:49:18.026+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to 2024-01-01T00:00:00+00:00, run_after=2024-01-01T00:00:00+00:00
[2024-01-10T18:49:18.066+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.437 seconds
[2024-01-10T18:49:48.842+0000] {processor.py:153} INFO - Started process (PID=1286) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:49:48.846+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:49:48.850+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:49:48.849+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:49:49.193+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:49:49.335+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:49:49.335+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:49:49.456+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:49:49.456+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:49:49.533+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.704 seconds
[2024-01-10T18:50:20.285+0000] {processor.py:153} INFO - Started process (PID=1346) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:50:20.287+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:50:20.288+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:50:20.288+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:50:20.450+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:50:20.502+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:50:20.502+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:50:20.553+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:50:20.553+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:50:20.591+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.310 seconds
[2024-01-10T18:50:50.973+0000] {processor.py:153} INFO - Started process (PID=1432) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:50:50.974+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:50:50.976+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:50:50.976+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:50:51.188+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:50:51.255+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:50:51.254+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:50:51.327+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:50:51.327+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:50:51.376+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.414 seconds
[2024-01-10T18:51:21.463+0000] {processor.py:153} INFO - Started process (PID=1515) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:51:21.464+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:51:21.467+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:51:21.466+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:51:21.610+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:51:21.657+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:51:21.656+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:51:21.704+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:51:21.704+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:51:21.746+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.289 seconds
[2024-01-10T18:51:52.162+0000] {processor.py:153} INFO - Started process (PID=1591) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:51:52.163+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:51:52.164+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:51:52.164+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:51:52.285+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:51:52.337+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:51:52.336+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:51:52.397+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:51:52.397+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:51:52.445+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.288 seconds
[2024-01-10T18:52:22.543+0000] {processor.py:153} INFO - Started process (PID=1668) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:52:22.544+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:52:22.546+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:52:22.545+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:52:22.624+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:52:22.656+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:52:22.656+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:52:22.690+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:52:22.690+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:52:22.721+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.181 seconds
[2024-01-10T18:52:53.299+0000] {processor.py:153} INFO - Started process (PID=1744) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:52:53.300+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:52:53.301+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:52:53.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:52:53.359+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:52:53.384+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:52:53.384+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:52:53.409+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:52:53.408+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:52:53.443+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.146 seconds
[2024-01-10T18:53:23.596+0000] {processor.py:153} INFO - Started process (PID=1821) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:53:23.597+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:53:23.598+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:53:23.598+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:53:23.701+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:53:23.742+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:53:23.742+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:53:23.786+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:53:23.785+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:53:23.841+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.250 seconds
[2024-01-10T18:53:54.251+0000] {processor.py:153} INFO - Started process (PID=1913) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:53:54.252+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:53:54.254+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:53:54.254+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:53:54.366+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:53:54.405+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:53:54.404+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:53:54.458+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:53:54.457+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:53:54.502+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.256 seconds
[2024-01-10T18:54:24.629+0000] {processor.py:153} INFO - Started process (PID=1989) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:54:24.630+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:54:24.631+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:54:24.630+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:54:24.705+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:54:24.735+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:54:24.735+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:54:24.765+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:54:24.765+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:54:24.799+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.174 seconds
[2024-01-10T18:54:54.973+0000] {processor.py:153} INFO - Started process (PID=2069) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:54:54.975+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:54:54.977+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:54:54.976+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:54:55.127+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:54:55.183+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:54:55.183+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:54:55.269+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:54:55.269+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:54:55.328+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.362 seconds
[2024-01-10T18:55:25.497+0000] {processor.py:153} INFO - Started process (PID=2145) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:55:25.498+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:55:25.498+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:55:25.498+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:55:25.561+0000] {processor.py:753} INFO - DAG(s) dict_keys(['mysql_test_2']) retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:55:25.585+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:55:25.585+0000] {dag.py:2690} INFO - Sync 1 DAGs
[2024-01-10T18:55:25.613+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:55:25.612+0000] {dag.py:3441} INFO - Setting next_dagrun for mysql_test_2 to None, run_after=None
[2024-01-10T18:55:25.636+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.142 seconds
[2024-01-10T18:55:28.573+0000] {processor.py:153} INFO - Started process (PID=2146) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:55:28.574+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:55:28.575+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:55:28.575+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:55:28.833+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:55:28.827+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T18:55:28.834+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:55:28.863+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.295 seconds
[2024-01-10T18:55:59.593+0000] {processor.py:153} INFO - Started process (PID=2222) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:55:59.594+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:55:59.596+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:55:59.596+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:55:59.691+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:55:59.685+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T18:55:59.692+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:55:59.724+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.134 seconds
[2024-01-10T18:56:30.052+0000] {processor.py:153} INFO - Started process (PID=2298) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:56:30.053+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:56:30.055+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:56:30.055+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:56:30.174+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:56:30.169+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T18:56:30.175+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:56:30.216+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.169 seconds
[2024-01-10T18:57:00.339+0000] {processor.py:153} INFO - Started process (PID=2374) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:57:00.341+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:57:00.342+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:57:00.342+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:57:00.451+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:57:00.443+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T18:57:00.452+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:57:00.491+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.155 seconds
[2024-01-10T18:57:09.842+0000] {processor.py:153} INFO - Started process (PID=2393) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:57:09.843+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:57:09.844+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:57:09.843+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:57:09.943+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:57:09.936+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T18:57:09.944+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:57:09.972+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.134 seconds
[2024-01-10T18:57:40.888+0000] {processor.py:153} INFO - Started process (PID=2469) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:57:40.890+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:57:40.893+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:57:40.892+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:57:41.033+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:57:41.025+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T18:57:41.036+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:57:41.087+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.206 seconds
[2024-01-10T18:58:11.653+0000] {processor.py:153} INFO - Started process (PID=2545) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:58:11.654+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:58:11.656+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:58:11.656+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:58:11.775+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:58:11.768+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T18:58:11.776+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:58:11.815+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.167 seconds
[2024-01-10T18:58:42.017+0000] {processor.py:153} INFO - Started process (PID=2621) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:58:42.018+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:58:42.020+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:58:42.019+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:58:42.106+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:58:42.099+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T18:58:42.108+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:58:42.132+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.119 seconds
[2024-01-10T18:59:13.064+0000] {processor.py:153} INFO - Started process (PID=2698) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:59:13.068+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:59:13.071+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:59:13.070+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:59:13.316+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:59:13.304+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T18:59:13.319+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:59:13.372+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.323 seconds
[2024-01-10T18:59:43.926+0000] {processor.py:153} INFO - Started process (PID=2774) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:59:43.928+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T18:59:43.930+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:59:43.930+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:59:44.079+0000] {logging_mixin.py:137} INFO - [2024-01-10T18:59:44.069+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T18:59:44.080+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T18:59:44.130+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.211 seconds
[2024-01-10T19:00:15.091+0000] {processor.py:153} INFO - Started process (PID=2850) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:00:15.097+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T19:00:15.101+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:00:15.100+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:00:15.298+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:00:15.289+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T19:00:15.299+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:00:15.344+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.261 seconds
[2024-01-10T19:00:45.564+0000] {processor.py:153} INFO - Started process (PID=2926) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:00:45.566+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T19:00:45.567+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:00:45.567+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:00:45.693+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:00:45.687+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T19:00:45.694+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:00:45.725+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.166 seconds
[2024-01-10T19:01:15.839+0000] {processor.py:153} INFO - Started process (PID=3011) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:01:15.841+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T19:01:15.844+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:01:15.843+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:01:16.024+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:01:16.014+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T19:01:16.025+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:01:16.069+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.238 seconds
[2024-01-10T19:01:46.452+0000] {processor.py:153} INFO - Started process (PID=3086) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:01:46.454+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T19:01:46.456+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:01:46.456+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:01:46.638+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:01:46.626+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 63, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T19:01:46.640+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:01:46.688+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.244 seconds
[2024-01-10T19:05:08.228+0000] {processor.py:153} INFO - Started process (PID=54) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:05:08.229+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T19:05:08.232+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:05:08.232+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:05:08.511+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:05:08.496+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 61, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T19:05:08.513+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:05:08.599+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.377 seconds
[2024-01-10T19:05:39.379+0000] {processor.py:153} INFO - Started process (PID=130) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:05:39.380+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T19:05:39.381+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:05:39.381+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:05:39.454+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:05:39.448+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 61, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T19:05:39.455+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:05:39.478+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.102 seconds
[2024-01-10T19:07:32.273+0000] {processor.py:153} INFO - Started process (PID=54) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:07:32.275+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T19:07:32.278+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:07:32.277+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:07:32.548+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:07:32.540+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 61, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T19:07:32.550+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:07:32.592+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.331 seconds
[2024-01-10T19:08:02.758+0000] {processor.py:153} INFO - Started process (PID=130) to work on /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:08:02.759+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/mysql_test_2.py for tasks to queue
[2024-01-10T19:08:02.760+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:08:02.760+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:08:02.838+0000] {logging_mixin.py:137} INFO - [2024-01-10T19:08:02.834+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/mysql_test_2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mysql_test_2.py", line 61, in <module>
    dag=dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/slack/operators/slack_webhook.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 394, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 743, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to SlackWebhookOperator (task_id: send_slack). Invalid arguments were:
**kwargs: {'sql': '\n    SELECT jobinfo_test.table_1.company, position, location, review\n    FROM jobinfo_test.table_1\n    JOIN jobinfo_test.table_2\n    ON jobinfo_test.table_1.company = jobinfo_test.table_2.company;\n'}
[2024-01-10T19:08:02.839+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/mysql_test_2.py
[2024-01-10T19:08:02.862+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/mysql_test_2.py took 0.108 seconds
