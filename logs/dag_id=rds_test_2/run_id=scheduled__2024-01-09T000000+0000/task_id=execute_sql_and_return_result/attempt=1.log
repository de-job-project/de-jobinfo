[2024-01-11T17:26:34.632+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: rds_test_2.execute_sql_and_return_result scheduled__2024-01-09T00:00:00+00:00 [queued]>
[2024-01-11T17:26:34.668+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: rds_test_2.execute_sql_and_return_result scheduled__2024-01-09T00:00:00+00:00 [queued]>
[2024-01-11T17:26:34.669+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2024-01-11T17:26:34.670+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 2
[2024-01-11T17:26:34.671+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2024-01-11T17:26:34.710+0000] {taskinstance.py:1300} INFO - Executing <Task(PythonOperator): execute_sql_and_return_result> on 2024-01-09 00:00:00+00:00
[2024-01-11T17:26:34.720+0000] {standard_task_runner.py:55} INFO - Started process 167 to run task
[2024-01-11T17:26:34.729+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'rds_test_2', 'execute_sql_and_return_result', 'scheduled__2024-01-09T00:00:00+00:00', '--job-id', '80', '--raw', '--subdir', 'DAGS_FOLDER/rds_test_2.py', '--cfg-path', '/tmp/tmp0rpu9vu_']
[2024-01-11T17:26:34.731+0000] {standard_task_runner.py:83} INFO - Job 80: Subtask execute_sql_and_return_result
[2024-01-11T17:26:34.926+0000] {task_command.py:388} INFO - Running <TaskInstance: rds_test_2.execute_sql_and_return_result scheduled__2024-01-09T00:00:00+00:00 [running]> on host 3d6f932ce29c
[2024-01-11T17:26:35.104+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=rds_test_2
AIRFLOW_CTX_TASK_ID=execute_sql_and_return_result
AIRFLOW_CTX_EXECUTION_DATE=2024-01-09T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-01-09T00:00:00+00:00
[2024-01-11T17:26:35.212+0000] {python.py:177} INFO - Done. Returned value was: +----------+------------------------+------------------------------------------------------------------------+-------------+-------------+------------+----------------------------------------+--------------------------------------------------------------+----------------------------------------------------------------+----------------+
| company  |        position        |                                 skills                                 |   location  |    career   |  due_date  |             review_summary             |                        merit_summary                         |                        demerit_summary                         | average_salary |
+----------+------------------------+------------------------------------------------------------------------+-------------+-------------+------------+----------------------------------------+--------------------------------------------------------------+----------------------------------------------------------------+----------------+
| 페이히어 | 서버 엔지니어 (Python) |                Python· Django· Flask· FastAPI· REST API                | 서울 강남구 | 경력 3~15년 |    상시    |   회사, 기업, 야근, 사람, 성장, 분야   | 지원, 점심, 복지, 제공, 환경, 강남역, 회사, 업무, 직원, 휴가 | 문제, 생각, 마인드, 야근, 개발, 그것, 복잡, 안정성, 기능, 기업 |   4,503 만원   |
| 페이히어 |     데이터엔지니어     | Python· SQL· Redash· Pandas· AWS· GCP· Spark· Airflow· Google BigQuery | 서울 강남구 |  경력 3~9년 |    상시    |   회사, 기업, 야근, 사람, 성장, 분야   | 지원, 점심, 복지, 제공, 환경, 강남역, 회사, 업무, 직원, 휴가 | 문제, 생각, 마인드, 야근, 개발, 그것, 복잡, 안정성, 기능, 기업 |   4,503 만원   |
| 페이히어 |      데이터분석가      |                             SQL· R· Python                             | 서울 강남구 |  경력 3~9년 |    상시    |   회사, 기업, 야근, 사람, 성장, 분야   | 지원, 점심, 복지, 제공, 환경, 강남역, 회사, 업무, 직원, 휴가 | 문제, 생각, 마인드, 야근, 개발, 그것, 복잡, 안정성, 기능, 기업 |   4,503 만원   |
| 딥노이드 |     데이터엔지니어     |            Python· Spark· Elasticsearch· Airflow· Git· Java            | 서울 구로구 | 경력 2~10년 | 2024-02-29 | 성장, 회사, 기업, 분위기, 관심, 경영진 |                     성장, 사람, 자유로운                     |        회사, 제품, 커리어, 조직, 미흡, 연봉, 수익, 능력        |   4,471 만원   |
| 페이히어 |   서버 엔지니어 (Go)   |           Python· FastAPI· REST API· Go· Golang· NoSql· AWS            | 서울 강남구 |  경력 2~5년 |    상시    |   회사, 기업, 야근, 사람, 성장, 분야   | 지원, 점심, 복지, 제공, 환경, 강남역, 회사, 업무, 직원, 휴가 | 문제, 생각, 마인드, 야근, 개발, 그것, 복잡, 안정성, 기능, 기업 |   4,503 만원   |
+----------+------------------------+------------------------------------------------------------------------+-------------+-------------+------------+----------------------------------------+--------------------------------------------------------------+----------------------------------------------------------------+----------------+
[2024-01-11T17:26:35.235+0000] {xcom.py:635} ERROR - Object of type PrettyTable is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2024-01-11T17:26:35.239+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2297, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type PrettyTable is not JSON serializable
[2024-01-11T17:26:35.259+0000] {taskinstance.py:1323} INFO - Marking task as UP_FOR_RETRY. dag_id=rds_test_2, task_id=execute_sql_and_return_result, execution_date=20240109T000000, start_date=20240111T172634, end_date=20240111T172635
[2024-01-11T17:26:35.287+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 80 for task execute_sql_and_return_result (Object of type PrettyTable is not JSON serializable; 167)
[2024-01-11T17:26:35.342+0000] {local_task_job.py:208} INFO - Task exited with return code 1
[2024-01-11T17:26:35.390+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
